{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":30892,"databundleVersionId":2715462,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary\n!pip install torchgeometry","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:08.238294Z","iopub.execute_input":"2023-11-15T15:29:08.238748Z","iopub.status.idle":"2023-11-15T15:29:32.976830Z","shell.execute_reply.started":"2023-11-15T15:29:08.238718Z","shell.execute_reply":"2023-11-15T15:29:32.975490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\nfrom torchgeometry.losses import one_hot\nimport os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport cv2\nimport time\nimport imageio\nimport matplotlib.pyplot as plt\nimport time\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch import Tensor\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.transforms import RandomRotation, Resize, PILToTensor, ToPILImage, Compose, InterpolationMode, functional\nfrom collections import OrderedDict\nimport wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-15T15:29:32.979418Z","iopub.execute_input":"2023-11-15T15:29:32.979789Z","iopub.status.idle":"2023-11-15T15:29:32.991120Z","shell.execute_reply.started":"2023-11-15T15:29:32.979759Z","shell.execute_reply":"2023-11-15T15:29:32.989672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi -L","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:32.992769Z","iopub.execute_input":"2023-11-15T15:29:32.993269Z","iopub.status.idle":"2023-11-15T15:29:34.069234Z","shell.execute_reply.started":"2023-11-15T15:29:32.993216Z","shell.execute_reply":"2023-11-15T15:29:34.067996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.071323Z","iopub.execute_input":"2023-11-15T15:29:34.071742Z","iopub.status.idle":"2023-11-15T15:29:34.080974Z","shell.execute_reply.started":"2023-11-15T15:29:34.071704Z","shell.execute_reply":"2023-11-15T15:29:34.079995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"# Number of class in the data set (3: neoplastic, non neoplastic, background)\nnum_classes = 3\n\n# Number of epoch\nepochs = 20\n\n# Hyperparameters for training \nlearning_rate = 6e-04\nbatch_size = 4\ndisplay_step = 50\n\n# Model path\ncheckpoint_path = '/kaggle/working/unet_model.pth'\npretrained_path = \"/kaggle/input/unet-checkpoint/unet_model.pth\"\n\n# Initialize lists to keep track of loss and accuracy\nloss_epoch_array = []\ntrain_accuracy = []\ntest_accuracy = []\nvalid_accuracy = []","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.084549Z","iopub.execute_input":"2023-11-15T15:29:34.084885Z","iopub.status.idle":"2023-11-15T15:29:34.091762Z","shell.execute_reply.started":"2023-11-15T15:29:34.084860Z","shell.execute_reply":"2023-11-15T15:29:34.090706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"transform = Compose([Resize((800, 1120), interpolation=InterpolationMode.BILINEAR),\n                     PILToTensor()])\nrotater = RandomRotation(180)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.092892Z","iopub.execute_input":"2023-11-15T15:29:34.093163Z","iopub.status.idle":"2023-11-15T15:29:34.101814Z","shell.execute_reply.started":"2023-11-15T15:29:34.093139Z","shell.execute_reply":"2023-11-15T15:29:34.100653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNetDataClass(Dataset):\n    def __init__(self, images_path, masks_path, transform):\n        super(UNetDataClass, self).__init__()\n        \n        images_list = os.listdir(images_path)\n        masks_list = os.listdir(masks_path)\n        \n        images_list = [images_path + image_name for image_name in images_list]\n        masks_list = [masks_path + mask_name for mask_name in masks_list]\n        \n        self.images_list = images_list\n        self.masks_list = masks_list\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img_path = self.images_list[index]\n        mask_path = self.masks_list[index]\n        \n        # Open image and mask\n        data = Image.open(img_path)\n        label = Image.open(mask_path)\n        \n        # Normalize\n        data = self.transform(data) / 255\n        label = self.transform(label) / 255\n        \n        label = torch.where(label>0.65, 1.0, 0.0)\n        \n        label[2, :, :] = 0.0001\n        label = torch.argmax(label, 0).type(torch.int64)\n        \n        return data, label\n    \n    def __len__(self):\n        return len(self.images_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.102993Z","iopub.execute_input":"2023-11-15T15:29:34.103347Z","iopub.status.idle":"2023-11-15T15:29:34.124492Z","shell.execute_reply.started":"2023-11-15T15:29:34.103316Z","shell.execute_reply":"2023-11-15T15:29:34.123299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\nmasks_path =  \"/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt/\"","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.125905Z","iopub.execute_input":"2023-11-15T15:29:34.126300Z","iopub.status.idle":"2023-11-15T15:29:34.138013Z","shell.execute_reply.started":"2023-11-15T15:29:34.126260Z","shell.execute_reply":"2023-11-15T15:29:34.136958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet_dataset = UNetDataClass(images_path, masks_path, transform)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.139201Z","iopub.execute_input":"2023-11-15T15:29:34.139524Z","iopub.status.idle":"2023-11-15T15:29:34.152190Z","shell.execute_reply.started":"2023-11-15T15:29:34.139499Z","shell.execute_reply":"2023-11-15T15:29:34.151037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = 0.8\nvalid_size = 0.2","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.153222Z","iopub.execute_input":"2023-11-15T15:29:34.154907Z","iopub.status.idle":"2023-11-15T15:29:34.161354Z","shell.execute_reply.started":"2023-11-15T15:29:34.154880Z","shell.execute_reply":"2023-11-15T15:29:34.160265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set, valid_set = random_split(unet_dataset, \n                                    [int(train_size * len(unet_dataset)) , \n                                     int(valid_size * len(unet_dataset))])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.162646Z","iopub.execute_input":"2023-11-15T15:29:34.163466Z","iopub.status.idle":"2023-11-15T15:29:34.171089Z","shell.execute_reply.started":"2023-11-15T15:29:34.163429Z","shell.execute_reply":"2023-11-15T15:29:34.170215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nvalid_dataloader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.172832Z","iopub.execute_input":"2023-11-15T15:29:34.173211Z","iopub.status.idle":"2023-11-15T15:29:34.181320Z","shell.execute_reply.started":"2023-11-15T15:29:34.173177Z","shell.execute_reply":"2023-11-15T15:29:34.180296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"**Encoder Block**","metadata":{}},{"cell_type":"code","source":"class encoder_block(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(encoder_block, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        \n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.3)\n        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.dropout(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        \n        next_layer = self.max_pool(x)\n        skip_layer = x\n        \n        return next_layer, skip_layer","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.182751Z","iopub.execute_input":"2023-11-15T15:29:34.183786Z","iopub.status.idle":"2023-11-15T15:29:34.195890Z","shell.execute_reply.started":"2023-11-15T15:29:34.183748Z","shell.execute_reply":"2023-11-15T15:29:34.194961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Decoder block**","metadata":{}},{"cell_type":"code","source":"class decoder_block(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(decoder_block, self).__init__()\n        \n        self.transpose_conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n        \n        self.conv1 = nn.Conv2d(2 * out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        \n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.relu = nn.ReLU() \n        self.dropout = nn.Dropout(p=0.3)\n    \n    def forward(self, x, skip_layer):\n        x = self.transpose_conv(x)\n        x = torch.cat([x, skip_layer], axis=1)\n        \n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.dropout(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.201092Z","iopub.execute_input":"2023-11-15T15:29:34.201812Z","iopub.status.idle":"2023-11-15T15:29:34.211966Z","shell.execute_reply.started":"2023-11-15T15:29:34.201787Z","shell.execute_reply":"2023-11-15T15:29:34.211012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Bottle neck**","metadata":{}},{"cell_type":"code","source":"class bottleneck_block(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(bottleneck_block, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding='same')\n        \n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.3)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        \n        x = self.dropout(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.213205Z","iopub.execute_input":"2023-11-15T15:29:34.214033Z","iopub.status.idle":"2023-11-15T15:29:34.222478Z","shell.execute_reply.started":"2023-11-15T15:29:34.213998Z","shell.execute_reply":"2023-11-15T15:29:34.221595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Unet model**","metadata":{}},{"cell_type":"code","source":"# UNet model\nclass UNet(nn.Module):\n    def __init__(self, n_class=3):\n        super(UNet, self).__init__()\n        # Encoder blocks\n        self.enc1 = encoder_block(3, 64)\n        self.enc2 = encoder_block(64, 128)\n        self.enc3 = encoder_block(128, 256)\n        self.enc4 = encoder_block(256, 512)\n        \n        # Bottleneck block\n        self.bottleneck = bottleneck_block(512, 1024)\n        \n        # Decoder blocks\n        self.dec1 = decoder_block(1024, 512)\n        self.dec2 = decoder_block(512, 256)\n        self.dec3 = decoder_block(256, 128)\n        self.dec4 = decoder_block(128, 64)\n        \n        # 1x1 convolution\n        self.out = nn.Conv2d(64, n_class, kernel_size=1, padding='same')\n        \n    def forward(self, image):\n        n1, s1 = self.enc1(image)\n        n2, s2 = self.enc2(n1)\n        n3, s3 = self.enc3(n2)\n        n4, s4 = self.enc4(n3)\n        \n        n5 = self.bottleneck(n4)\n        \n        n6 = self.dec1(n5, s4)\n        n7 = self.dec2(n6, s3)\n        n8 = self.dec3(n7, s2)\n        n9 = self.dec4(n8, s1)\n        \n        output = self.out(n9)\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.223553Z","iopub.execute_input":"2023-11-15T15:29:34.223824Z","iopub.status.idle":"2023-11-15T15:29:34.237234Z","shell.execute_reply.started":"2023-11-15T15:29:34.223800Z","shell.execute_reply":"2023-11-15T15:29:34.236300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss function","metadata":{}},{"cell_type":"code","source":"class CEDiceLoss(nn.Module):\n    def __init__(self, weights) -> None:\n        super(CEDiceLoss, self).__init__()\n        self.eps: float = 1e-6\n        self.weights: torch.Tensor = weights\n\n    def forward(\n            self,\n            input: torch.Tensor,\n            target: torch.Tensor) -> torch.Tensor:\n        if not torch.is_tensor(input):\n            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n                            .format(type(input)))\n        if not len(input.shape) == 4:\n            raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n                             .format(input.shape))\n        if not input.shape[-2:] == target.shape[-2:]:\n            raise ValueError(\"input and target shapes must be the same. Got: {}\"\n                             .format(input.shape, input.shape))\n        if not input.device == target.device:\n            raise ValueError(\n                \"input and target must be in the same device. Got: {}\" .format(\n                    input.device, target.device))\n        if not self.weights.shape[1] == input.shape[1]:\n            raise ValueError(\"The number of weights must equal the number of classes\")\n        if not torch.sum(self.weights).item() == 1:\n            raise ValueError(\"The sum of all weights must equal 1\")\n            \n        # cross entropy loss\n        celoss = nn.CrossEntropyLoss(self.weights)(input, target)\n        \n        # compute softmax over the classes axis\n        input_soft = F.softmax(input, dim=1)\n\n        # create the labels one hot tensor\n        target_one_hot = one_hot(target, num_classes=input.shape[1],\n                                 device=input.device, dtype=input.dtype)\n\n        # compute the actual dice score\n        dims = (2, 3)\n        intersection = torch.sum(input_soft * target_one_hot, dims)\n        cardinality = torch.sum(input_soft + target_one_hot, dims)\n\n        dice_score = 2. * intersection / (cardinality + self.eps)\n        \n        dice_score = torch.sum(dice_score * self.weights, dim=1)\n        \n        return torch.mean(1. - dice_score) + celoss","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.238938Z","iopub.execute_input":"2023-11-15T15:29:34.239291Z","iopub.status.idle":"2023-11-15T15:29:34.253414Z","shell.execute_reply.started":"2023-11-15T15:29:34.239256Z","shell.execute_reply":"2023-11-15T15:29:34.252455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"**Initialize weights**","metadata":{}},{"cell_type":"code","source":"def weights_init(model):\n    if isinstance(model, nn.Linear):\n        # Xavier Distribution\n        torch.nn.init.xavier_uniform_(model.weight)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.254716Z","iopub.execute_input":"2023-11-15T15:29:34.255364Z","iopub.status.idle":"2023-11-15T15:29:34.265596Z","shell.execute_reply.started":"2023-11-15T15:29:34.255329Z","shell.execute_reply":"2023-11-15T15:29:34.264625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_model(model, optimizer, path):\n    checkpoint = {\n        \"model\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }\n    torch.save(checkpoint, path)\n\ndef load_model(model, optimizer, path):\n    checkpoint = torch.load(path)\n    model.load_state_dict(checkpoint[\"model\"])\n    optimizer.load_state_dict(checkpoint['optimizer'])\n    return model, optimizer","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.266811Z","iopub.execute_input":"2023-11-15T15:29:34.267140Z","iopub.status.idle":"2023-11-15T15:29:34.274953Z","shell.execute_reply.started":"2023-11-15T15:29:34.267110Z","shell.execute_reply":"2023-11-15T15:29:34.273929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train model**","metadata":{}},{"cell_type":"code","source":"# Train function for each epoch\ndef train(train_dataloader, valid_dataloader,learing_rate_scheduler, epoch, display_step):\n    print(f\"Start epoch #{epoch+1}, learning rate for this epoch: {learing_rate_scheduler.get_last_lr()}\")\n    start_time = time.time()\n    train_loss_epoch = 0\n    test_loss_epoch = 0\n    last_loss = 999999999\n    model.train()\n    for i, (data,targets) in enumerate(train_dataloader):\n        \n        # Load data into GPU\n        data, targets = data.to(device), targets.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(data)\n\n        # Backpropagation, compute gradients\n        loss = loss_function(outputs, targets.long())\n        loss.backward()\n\n        # Apply gradients\n        optimizer.step()\n        \n        # Save loss\n        train_loss_epoch += loss.item()\n        if (i+1) % display_step == 0:\n#             accuracy = float(test(test_loader))\n            print('Train Epoch: {} [{}/{} ({}%)]\\tLoss: {:.4f}'.format(\n                epoch + 1, (i+1) * len(data), len(train_dataloader.dataset), 100 * (i+1) * len(data) / len(train_dataloader.dataset), \n                loss.item()))\n                  \n    print(f\"Done epoch #{epoch+1}, time for this epoch: {time.time()-start_time}s\")\n    train_loss_epoch/= (i + 1)\n    \n    # Evaluate the validation set\n    model.eval()\n    with torch.no_grad():\n        for data, target in valid_dataloader:\n            data, target = data.to(device), target.to(device)\n            test_output = model(data)\n            test_loss = loss_function(test_output, target)\n            test_loss_epoch += test_loss.item()\n            \n    test_loss_epoch/= (i+1)\n    \n    return train_loss_epoch , test_loss_epoch","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.278606Z","iopub.execute_input":"2023-11-15T15:29:34.279037Z","iopub.status.idle":"2023-11-15T15:29:34.290010Z","shell.execute_reply.started":"2023-11-15T15:29:34.279013Z","shell.execute_reply":"2023-11-15T15:29:34.289046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test function\ndef test(dataloader):\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for i, (data, targets) in enumerate(dataloader):\n            data, targets = data.to(device), targets.to(device)\n            outputs = model(data)\n            _, pred = torch.max(outputs, 1)\n            test_loss += targets.size(0)\n            correct += torch.sum(pred == targets).item()\n    return 100.0 * correct / test_loss","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.291440Z","iopub.execute_input":"2023-11-15T15:29:34.291989Z","iopub.status.idle":"2023-11-15T15:29:34.302918Z","shell.execute_reply.started":"2023-11-15T15:29:34.291964Z","shell.execute_reply":"2023-11-15T15:29:34.301997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = UNet()\n# model.apply(weights_init)\n# model = nn.DataParallel(model)\n# checkpoint = torch.load(pretrained_path)\n\n# new_state_dict = OrderedDict()\n# for k, v in checkpoint['model'].items():\n#     name = k[7:] # remove `module.`\n#     new_state_dict[name] = v\n# load params\n# model.load_state_dict(new_state_dict)\nmodel = nn.DataParallel(model)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.304330Z","iopub.execute_input":"2023-11-15T15:29:34.304708Z","iopub.status.idle":"2023-11-15T15:29:34.597477Z","shell.execute_reply.started":"2023-11-15T15:29:34.304671Z","shell.execute_reply":"2023-11-15T15:29:34.596389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights = torch.Tensor([[0.4, 0.55, 0.05]]).cuda()\nloss_function = CEDiceLoss(weights)\n\n# Define the optimizer (Adam optimizer)\noptimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n# optimizer.load_state_dict(checkpoint['optimizer'])\n\n# Learning rate scheduler\nlearing_rate_scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.6)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.598815Z","iopub.execute_input":"2023-11-15T15:29:34.599179Z","iopub.status.idle":"2023-11-15T15:29:34.609304Z","shell.execute_reply.started":"2023-11-15T15:29:34.599145Z","shell.execute_reply":"2023-11-15T15:29:34.608316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_model(model, optimizer, checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.610792Z","iopub.execute_input":"2023-11-15T15:29:34.611407Z","iopub.status.idle":"2023-11-15T15:29:34.934162Z","shell.execute_reply.started":"2023-11-15T15:29:34.611372Z","shell.execute_reply":"2023-11-15T15:29:34.933030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.login(\n    # set the wandb project where this run will be logged\n#     project= \"PolypSegment\", \n    key = \"1658d378d091cf8659e37004bc727f76b3de8356\",\n)\nwandb.init(\n    project = \"PolypSegment\"\n)\n# Training loop\ntrain_loss_array = []\ntest_loss_array = []\nlast_loss = 9999999999999\nfor epoch in range(epochs):\n    train_loss_epoch = 0\n    test_loss_epoch = 0\n    (train_loss_epoch, test_loss_epoch) = train(train_dataloader, \n                                              valid_dataloader, \n                                              learing_rate_scheduler, epoch, display_step)\n    \n    if test_loss_epoch < last_loss:\n        save_model(model, optimizer, checkpoint_path)\n        last_loss = test_loss_epoch\n        \n    learing_rate_scheduler.step()\n    train_loss_array.append(train_loss_epoch)\n    test_loss_array.append(test_loss_epoch)\n    \n    wandb.log({\"Train loss\": train_loss_epoch, \"Valid loss\": test_loss_epoch})\n#     train_accuracy.append(test(train_loader))\n#     valid_accuracy.append(test(test_loader))\n#     print(\"Epoch {}: loss: {:.4f}, train accuracy: {:.4f}, valid accuracy:{:.4f}\".format(epoch + 1, \n#                                         train_loss_array[-1], train_accuracy[-1], valid_accuracy[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:29:34.935703Z","iopub.execute_input":"2023-11-15T15:29:34.936077Z","iopub.status.idle":"2023-11-15T15:30:13.312710Z","shell.execute_reply.started":"2023-11-15T15:29:34.936035Z","shell.execute_reply":"2023-11-15T15:30:13.311157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.313909Z","iopub.status.idle":"2023-11-15T15:30:13.314466Z","shell.execute_reply.started":"2023-11-15T15:30:13.314178Z","shell.execute_reply":"2023-11-15T15:30:13.314204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot the learning cure","metadata":{}},{"cell_type":"code","source":"# load_model(model, checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.315609Z","iopub.status.idle":"2023-11-15T15:30:13.316071Z","shell.execute_reply.started":"2023-11-15T15:30:13.315819Z","shell.execute_reply":"2023-11-15T15:30:13.315841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.dpi'] = 90\nplt.rcParams['figure.figsize'] = (6, 4)\nepochs_array = range(epochs)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.318233Z","iopub.status.idle":"2023-11-15T15:30:13.318607Z","shell.execute_reply.started":"2023-11-15T15:30:13.318439Z","shell.execute_reply":"2023-11-15T15:30:13.318456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Training and Test loss\nplt.plot(epochs_array, train_loss_array, 'g', label='Training loss')\nplt.plot(epochs_array, test_loss_array, 'b', label='Test loss')\nplt.title('Training and Test loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.320505Z","iopub.status.idle":"2023-11-15T15:30:13.320856Z","shell.execute_reply.started":"2023-11-15T15:30:13.320689Z","shell.execute_reply":"2023-11-15T15:30:13.320706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Infer**","metadata":{}},{"cell_type":"code","source":"# from torch.jit import load\n# model = UNet()\n# optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n\n# checkpoint = torch.load(pretrained_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.321975Z","iopub.status.idle":"2023-11-15T15:30:13.322374Z","shell.execute_reply.started":"2023-11-15T15:30:13.322153Z","shell.execute_reply":"2023-11-15T15:30:13.322170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optimizer.load_state_dict(checkpoint['optimizer'])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.324175Z","iopub.status.idle":"2023-11-15T15:30:13.324916Z","shell.execute_reply.started":"2023-11-15T15:30:13.324707Z","shell.execute_reply":"2023-11-15T15:30:13.324734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from collections import OrderedDict\n# new_state_dict = OrderedDict()\n# for k, v in checkpoint['model'].items():\n#     name = k[7:] # remove `module.`\n#     new_state_dict[name] = v\n# # load params\n# model.load_state_dict(new_state_dict)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.326167Z","iopub.status.idle":"2023-11-15T15:30:13.326542Z","shell.execute_reply.started":"2023-11-15T15:30:13.326373Z","shell.execute_reply":"2023-11-15T15:30:13.326390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualize results**","metadata":{}},{"cell_type":"code","source":"for i, (data, label) in enumerate(train_dataloader):\n    img = data\n    mask = label\n    break","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.328343Z","iopub.status.idle":"2023-11-15T15:30:13.328716Z","shell.execute_reply.started":"2023-11-15T15:30:13.328532Z","shell.execute_reply":"2023-11-15T15:30:13.328549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, arr = plt.subplots(4, 3, figsize=(16, 12))\narr[0][0].set_title('Image')\narr[0][1].set_title('Segmentation')\narr[0][2].set_title('Predict')\n\nmodel.eval()\nwith torch.no_grad():\n    predict = model(img)\n\nfor i in range(4):\n    arr[i][0].imshow(img[i].permute(1, 2, 0));\n    \n    arr[i][1].imshow(F.one_hot(mask[i]).float())\n    \n    arr[i][2].imshow(F.one_hot(torch.argmax(predict[i], 0).cpu()).float())","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.330102Z","iopub.status.idle":"2023-11-15T15:30:13.330454Z","shell.execute_reply.started":"2023-11-15T15:30:13.330288Z","shell.execute_reply":"2023-11-15T15:30:13.330305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Create submission**","metadata":{}},{"cell_type":"code","source":"transform = Compose([Resize((800, 1120), interpolation=InterpolationMode.BILINEAR),\n                     PILToTensor()])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.332336Z","iopub.status.idle":"2023-11-15T15:30:13.332706Z","shell.execute_reply.started":"2023-11-15T15:30:13.332523Z","shell.execute_reply":"2023-11-15T15:30:13.332540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNetTestDataClass(Dataset):\n    def __init__(self, images_path, transform):\n        super(UNetTestDataClass, self).__init__()\n        \n        images_list = os.listdir(images_path)\n        images_list = [images_path+i for i in images_list]\n        \n        self.images_list = images_list\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img_path = self.images_list[index]\n        data = Image.open(img_path)\n        h = data.size[1]\n        w = data.size[0]\n        data = self.transform(data) / 255        \n        return data, img_path, h, w\n    \n    def __len__(self):\n        return len(self.images_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.334372Z","iopub.status.idle":"2023-11-15T15:30:13.334712Z","shell.execute_reply.started":"2023-11-15T15:30:13.334547Z","shell.execute_reply":"2023-11-15T15:30:13.334563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/bkai-igh-neopolyp/test/test/'\nunet_test_dataset = UNetTestDataClass(path, transform)\ntest_dataloader = DataLoader(unet_test_dataset, batch_size=8, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.335688Z","iopub.status.idle":"2023-11-15T15:30:13.336019Z","shell.execute_reply.started":"2023-11-15T15:30:13.335856Z","shell.execute_reply":"2023-11-15T15:30:13.335871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, (data, path, h, w) in enumerate(test_dataloader):\n    img = data\n    break","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.337579Z","iopub.status.idle":"2023-11-15T15:30:13.337938Z","shell.execute_reply.started":"2023-11-15T15:30:13.337765Z","shell.execute_reply":"2023-11-15T15:30:13.337781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, arr = plt.subplots(5, 2, figsize=(16, 12))\narr[0][0].set_title('Image');\narr[0][1].set_title('Predict');\n\nmodel.eval()\nwith torch.no_grad():\n    predict = model(img)\n\nfor i in range(5):\n    arr[i][0].imshow(img[i].permute(1, 2, 0));\n    arr[i][1].imshow(F.one_hot(torch.argmax(predict[i], 0).cpu()).float())","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.340165Z","iopub.status.idle":"2023-11-15T15:30:13.340536Z","shell.execute_reply.started":"2023-11-15T15:30:13.340367Z","shell.execute_reply":"2023-11-15T15:30:13.340384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nif not os.path.isdir(\"/kaggle/working/predicted_masks\"):\n    os.mkdir(\"/kaggle/working/predicted_masks\")\nfor _, (img, path, H, W) in enumerate(test_dataloader):\n    a = path\n    b = img\n    h = H\n    w = W\n    \n    with torch.no_grad():\n        predicted_mask = model(b)\n    for i in range(len(a)):\n        image_id = a[i].split('/')[-1].split('.')[0]\n        filename = image_id + \".png\"\n        mask2img = Resize((h[i].item(), w[i].item()), interpolation=InterpolationMode.NEAREST)(ToPILImage()(F.one_hot(torch.argmax(predicted_mask[i], 0)).permute(2, 0, 1).float()))\n        mask2img.save(os.path.join(\"/kaggle/working/predicted_masks/\", filename))","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.341827Z","iopub.status.idle":"2023-11-15T15:30:13.342191Z","shell.execute_reply.started":"2023-11-15T15:30:13.342009Z","shell.execute_reply":"2023-11-15T15:30:13.342026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 0] = 255\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    \n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    return rle_to_string(rle)\n\ndef mask2string(dir):\n    ## mask --> string\n    strings = []\n    ids = []\n    ws, hs = [[] for i in range(2)]\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n        print(path)\n        img = cv2.imread(path)[:,:,::-1]\n        h, w = img.shape[0], img.shape[1]\n        for channel in range(2):\n            ws.append(w)\n            hs.append(h)\n            ids.append(f'{id}_{channel}')\n            string = rle_encode_one_mask(img[:,:,channel])\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r\n\n\nMASK_DIR_PATH = '/kaggle/working/predicted_masks' # change this to the path to your output mask folder\ndir = MASK_DIR_PATH\nres = mask2string(dir)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\ndf.to_csv(r'submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T15:30:13.344299Z","iopub.status.idle":"2023-11-15T15:30:13.344669Z","shell.execute_reply.started":"2023-11-15T15:30:13.344492Z","shell.execute_reply":"2023-11-15T15:30:13.344509Z"},"trusted":true},"execution_count":null,"outputs":[]}]}